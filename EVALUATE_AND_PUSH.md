# H∆∞·ªõng d·∫´n Evaluate v√† Push Model l√™n Hugging Face

## B∆∞·ªõc 1: Ki·ªÉm tra Training ƒë√£ ho√†n th√†nh

Sau khi training xong (15 epochs, ~10-12 gi·ªù), ki·ªÉm tra:

```bash
# Xem log cu·ªëi c√πng
tail -100 logs/training_baseline*.log

# Ki·ªÉm tra checkpoint cu·ªëi
ls -lh outputs/checkpoints/
```

T√¨m d√≤ng: `***** train completed *****` ho·∫∑c t∆∞∆°ng t·ª± ƒë·ªÉ confirm training xong.

## B∆∞·ªõc 2: Evaluate Model

### 2.1. Ch·∫°y evaluation tr√™n test set

```bash
cd /mnt/nghiepth/giangha/visempar/ViSemPar_new1
conda activate baseline_final

# Evaluate tr√™n public test
python train_baseline.py --eval-only --checkpoint outputs/checkpoints/checkpoint-XXXX

# Ho·∫∑c d√πng script evaluate ri√™ng (n·∫øu c√≥)
python evaluate.py --model-path outputs/checkpoints/checkpoint-XXXX \
                   --test-file data/public_test.txt \
                   --output predictions_public.txt
```

### 2.2. T√≠nh SMATCH score

```bash
# So s√°nh v·ªõi ground truth
python calculate_smatch.py \
    --predictions predictions_public.txt \
    --gold data/public_test_ground_truth.txt

# K·∫øt qu·∫£ s·∫Ω hi·ªÉn th·ªã:
# Precision: X.XX
# Recall: X.XX
# F1 (SMATCH): X.XX
```

### 2.3. Ki·ªÉm tra m·ªôt v√†i v√≠ d·ª•

```bash
# Xem 10 predictions ƒë·∫ßu ti√™n
head -20 predictions_public.txt

# So s√°nh v·ªõi ground truth
paste <(head -20 predictions_public.txt) <(head -20 data/public_test_ground_truth.txt) | column -t
```

## B∆∞·ªõc 3: So s√°nh v·ªõi MTUP 7B

```bash
echo "=== BASELINE 7B vs MTUP 7B Comparison ==="
echo ""
echo "BASELINE 7B (Single-task):"
echo "  F1 Score: [ƒêi·ªÅn score c·ªßa b·∫°n]"
echo ""
echo "MTUP 7B (Multi-task):"
echo "  F1 Score: [ƒêi·ªÅn score MTUP]"
echo ""
echo "Difference: [T√≠nh hi·ªáu s·ªë]"
```

## B∆∞·ªõc 4: Chu·∫©n b·ªã Model ƒë·ªÉ Push

### 4.1. T·∫°o model card (README.md)

```bash
# T·∫°o README cho model
cat > model_card.md << 'EOF'
---
language: vi
license: apache-2.0
tags:
- vietnamese
- amr
- semantic-parsing
- qwen2.5
datasets:
- vlsp2024-amr
metrics:
- smatch
model-index:
- name: vietnamese-amr-baseline-7b
  results:
  - task:
      type: semantic-parsing
      name: AMR Parsing
    dataset:
      type: vlsp2024-amr
      name: VLSP 2024 Vietnamese AMR
    metrics:
    - type: smatch
      value: [ƒêI·ªÄN F1 SCORE C·ª¶A B·∫†N]
      name: SMATCH F1
---

# Vietnamese AMR Baseline 7B

Baseline model for Vietnamese Abstract Meaning Representation (AMR) parsing, trained on VLSP 2024 dataset.

## Model Details

- **Base Model**: Qwen/Qwen2.5-7B-Instruct
- **Training Approach**: Single-task (baseline) with LoRA
- **Language**: Vietnamese
- **Task**: AMR Semantic Parsing

## Training Configuration

```yaml
Model: Qwen 2.5 7B Instruct
LoRA Rank: 64
Max Sequence Length: 256
Batch Size: 1 (with gradient accumulation 16)
Epochs: 15
Learning Rate: 2e-4
Optimizer: AdamW
Precision: BF16
Gradient Checkpointing: Enabled
```

## Performance

| Metric | Score |
|--------|-------|
| SMATCH F1 | [ƒêI·ªÄN SCORE] |
| Precision | [ƒêI·ªÄN SCORE] |
| Recall | [ƒêI·ªÄN SCORE] |

## Comparison with MTUP

This baseline model is trained for comparison with Multi-Task Unified Pre-training (MTUP) approach.

| Model | Approach | F1 Score |
|-------|----------|----------|
| Baseline 7B | Single-task | [ƒêI·ªÄN SCORE] |
| MTUP 7B | Multi-task | [ƒêI·ªÄN SCORE] |

## Usage

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# Load base model
base_model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

# Load LoRA adapter
model = PeftModel.from_pretrained(base_model, "YOUR_USERNAME/vietnamese-amr-baseline-7b")

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B-Instruct")

# Inference
prompt = """B·∫°n l√† chuy√™n gia ph√¢n t√≠ch ng·ªØ nghƒ©a ti·∫øng Vi·ªát. H√£y chuy·ªÉn ƒë·ªïi c√¢u sau sang ƒë·ªãnh d·∫°ng AMR.

C√¢u ti·∫øng Vi·ªát: Ch·ªß t·ªãch n∆∞·ªõc ƒë√£ ph√°t bi·ªÉu t·∫°i h·ªôi ngh·ªã.

AMR:
"""

inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.1)
amr = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(amr)
```

## Training Details

See [training logs](logs/) and [configuration](config/config.py) for full details.

## Citation

```bibtex
@misc{vietnamese-amr-baseline-7b,
  author = {[T√äN C·ª¶A B·∫†N]},
  title = {Vietnamese AMR Baseline 7B},
  year = {2025},
  publisher = {HuggingFace},
  url = {https://huggingface.co/[YOUR_USERNAME]/vietnamese-amr-baseline-7b}
}
```
EOF
```

### 4.2. Merge LoRA weights (optional - ƒë·ªÉ model d·ªÖ d√πng h∆°n)

```python
# merge_lora.py
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import torch

print("Loading base model...")
base_model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

print("Loading LoRA adapter...")
model = PeftModel.from_pretrained(
    base_model,
    "outputs/checkpoints/checkpoint-XXXX"  # Best checkpoint
)

print("Merging LoRA weights...")
merged_model = model.merge_and_unload()

print("Saving merged model...")
merged_model.save_pretrained("merged_model")

print("Saving tokenizer...")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B-Instruct")
tokenizer.save_pretrained("merged_model")

print("Done!")
```

Ch·∫°y:
```bash
python merge_lora.py
```

## B∆∞·ªõc 5: Push l√™n Hugging Face

### 5.1. Login v√†o Hugging Face

```bash
# Install huggingface-cli n·∫øu ch∆∞a c√≥
pip install huggingface_hub

# Login (c·∫ßn token t·ª´ https://huggingface.co/settings/tokens)
huggingface-cli login
# Paste token khi ƒë∆∞·ª£c h·ªèi
```

### 5.2. T·∫°o repository

```bash
# T·∫°o repo m·ªõi
huggingface-cli repo create vietnamese-amr-baseline-7b --type model

# Ho·∫∑c d√πng Python
python << 'EOF'
from huggingface_hub import HfApi
api = HfApi()
api.create_repo(
    repo_id="vietnamese-amr-baseline-7b",
    repo_type="model",
    private=False  # public repo
)
EOF
```

### 5.3. Upload model

**Option 1: Upload LoRA adapter (nh·∫π h∆°n, ~200MB)**

```bash
cd outputs/checkpoints/checkpoint-XXXX  # Best checkpoint

# Copy model card
cp /path/to/model_card.md README.md

# Upload
huggingface-cli upload YOUR_USERNAME/vietnamese-amr-baseline-7b . . --repo-type model
```

**Option 2: Upload merged model (ƒë·∫ßy ƒë·ªß, ~14GB)**

```bash
cd merged_model

# Copy model card
cp /path/to/model_card.md README.md

# Upload
huggingface-cli upload YOUR_USERNAME/vietnamese-amr-baseline-7b . . --repo-type model
```

**Option 3: Upload b·∫±ng Python (recommended - c√≥ progress bar)**

```python
# upload_to_hf.py
from huggingface_hub import HfApi
import os

api = HfApi()
repo_id = "YOUR_USERNAME/vietnamese-amr-baseline-7b"

# Option 1: Upload LoRA adapter
checkpoint_dir = "outputs/checkpoints/checkpoint-XXXX"

# Option 2: Upload merged model
# checkpoint_dir = "merged_model"

print(f"Uploading {checkpoint_dir} to {repo_id}...")

api.upload_folder(
    folder_path=checkpoint_dir,
    repo_id=repo_id,
    repo_type="model",
    commit_message="Upload Vietnamese AMR Baseline 7B model"
)

# Upload README
api.upload_file(
    path_or_fileobj="model_card.md",
    path_in_repo="README.md",
    repo_id=repo_id,
    repo_type="model"
)

print(f"‚úì Model uploaded to https://huggingface.co/{repo_id}")
```

Ch·∫°y:
```bash
python upload_to_hf.py
```

## B∆∞·ªõc 6: Verify Model tr√™n Hugging Face

1. M·ªü https://huggingface.co/YOUR_USERNAME/vietnamese-amr-baseline-7b
2. Ki·ªÉm tra:
   - ‚úì Model card hi·ªÉn th·ªã ƒë√∫ng
   - ‚úì Files ƒë√£ upload ƒë·∫ßy ƒë·ªß
   - ‚úì Metrics hi·ªÉn th·ªã
3. Test model b·∫±ng Inference API (n·∫øu c√≥)

## B∆∞·ªõc 7: T·∫°o Summary Report

```bash
cat > TRAINING_REPORT.md << 'EOF'
# Vietnamese AMR Baseline 7B - Training Report

## Training Summary

- **Start Time**: [ƒêI·ªÄN TH·ªúI GIAN B·∫ÆT ƒê·∫¶U]
- **End Time**: [ƒêI·ªÄN TH·ªúI GIAN K·∫æT TH√öC]
- **Total Duration**: ~XX hours
- **GPU**: NVIDIA RTX A6000 (48GB)
- **Final Loss**: [ƒêI·ªÄN LOSS CU·ªêI]

## Evaluation Results

### Public Test Set

| Metric | Score |
|--------|-------|
| SMATCH F1 | XX.XX |
| Precision | XX.XX |
| Recall | XX.XX |

### Comparison with MTUP

| Model | F1 Score | Difference |
|-------|----------|------------|
| MTUP 7B | XX.XX | - |
| Baseline 7B | XX.XX | ¬±X.XX |

## Model Location

- **Hugging Face**: https://huggingface.co/YOUR_USERNAME/vietnamese-amr-baseline-7b
- **Local Checkpoint**: outputs/checkpoints/checkpoint-XXXX

## Key Findings

[ƒêI·ªÄN NH·∫¨N X√âT C·ª¶A B·∫†N]
- Baseline so v·ªõi MTUP: ...
- Training stability: ...
- Best practices: ...

## Next Steps

- [ ] Test on private test set
- [ ] Compare with other baselines
- [ ] Analyze error cases
- [ ] Write paper/report
EOF
```

## T√≥m t·∫Øt Commands

```bash
# 1. Evaluate
python train_baseline.py --eval-only --checkpoint outputs/checkpoints/checkpoint-XXXX

# 2. Calculate SMATCH
python calculate_smatch.py --predictions predictions.txt --gold ground_truth.txt

# 3. Login Hugging Face
huggingface-cli login

# 4. Upload model
python upload_to_hf.py

# 5. Verify
firefox https://huggingface.co/YOUR_USERNAME/vietnamese-amr-baseline-7b
```

## L∆∞u √Ω quan tr·ªçng

1. **Ch·ªçn best checkpoint**: D·ª±a v√†o validation loss, kh√¥ng ph·∫£i checkpoint cu·ªëi c√πng
2. **Test tr∆∞·ªõc khi upload**: Ch·∫°y inference v√†i v√≠ d·ª• ƒë·ªÉ ƒë·∫£m b·∫£o model ho·∫°t ƒë·ªông
3. **Ghi r√µ config**: Document t·∫•t c·∫£ hyperparameters ƒë·ªÉ reproduce ƒë∆∞·ª£c
4. **So s√°nh fair**: ƒê·∫£m b·∫£o MTUP v√† Baseline d√πng c√πng test set v√† metric
5. **Backup**: L∆∞u checkpoint t·ªët nh·∫•t ·ªü nhi·ªÅu n∆°i

Ch√∫c b·∫°n th√†nh c√¥ng! üöÄ
