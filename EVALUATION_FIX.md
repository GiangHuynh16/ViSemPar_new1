# ðŸ”§ Evaluation Fix Applied - ROOT CAUSE FOUND!

## âœ… CRITICAL BUG IDENTIFIED

### The Problem
Model was generating garbage output with excessive parentheses:
```
(((((((((((((((((((((((((((((((((((((((((((((((((((((((c1:ARG0(c2:ARG1(
```

### ROOT CAUSE
**Prompt mismatch between training and evaluation!**

#### Training Prompt (Vietnamese - v2_natural template):
```
### NHIá»†M Vá»¤: Chuyá»ƒn Ä‘á»•i cÃ¢u tiáº¿ng Viá»‡t sang AMR (2 bÆ°á»›c)

### CÃ¢u cáº§n phÃ¢n tÃ­ch:
{sentence}

### Káº¿t quáº£ phÃ¢n tÃ­ch:

## BÆ°á»›c 1 - Táº¡o cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n):
{amr_no_vars}

## BÆ°á»›c 2 - GÃ¡n biáº¿n cho cÃ¡c khÃ¡i niá»‡m:
...
AMR hoÃ n chá»‰nh:
{amr_with_vars}
```

#### Evaluation Prompt (WRONG - English):
```
Sentence: {sentence}

Task 1: Generate AMR structure without variables.
Output:
```

**Model couldn't recognize the English prompt because it was ONLY trained on Vietnamese prompts!**

## Fix Applied

### Changes in `evaluate_mtup_model.py`:

1. **Replaced English prompt with Vietnamese training format**:
   ```python
   full_prompt = f"""### NHIá»†M Vá»¤: Chuyá»ƒn Ä‘á»•i cÃ¢u tiáº¿ng Viá»‡t sang AMR (2 bÆ°á»›c)

   ### CÃ¢u cáº§n phÃ¢n tÃ­ch:
   {sentence}

   ### Káº¿t quáº£ phÃ¢n tÃ­ch:

   ## BÆ°á»›c 1 - Táº¡o cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n):
   """
   ```

2. **Single-pass generation** (model generates both tasks at once)
   - Model was trained to complete the full template
   - No need for separate Task 1 + Task 2 calls

3. **Extract AMR from "AMR hoÃ n chá»‰nh:" section**
   - Parse the model's complete output
   - Extract final AMR after "BÆ°á»›c 2" header

4. **Greedy decoding** (deterministic)
   - `do_sample=False`
   - No temperature or top_p

## Next Steps - RUN ON SERVER

```bash
# 1. Pull latest changes
cd ~/ViSemPar_new1
git pull origin main

# 2. Run evaluation
bash RUN_EVALUATION.sh
# Choose option 1 (10 samples, ~2 min)

# 3. Expected result
# Should see valid SMATCH scores now!
```

## Expected Output

```
================================================================================
EVALUATION RESULTS
================================================================================

Processed: 10/10 examples  â† All should parse successfully!
Errors:    0

================================================================================
SMATCH SCORES
================================================================================
  Precision: 0.XXXX
  Recall:    0.XXXX
  F1:        0.XXXX  â† Should be > 0 now!
================================================================================
```

## Why This Should Work

1. âœ… **Prompt matches training** - Model recognizes Vietnamese template
2. âœ… **Greedy decoding** - Deterministic, stable output
3. âœ… **No post-processing** - Let model generate naturally
4. âœ… **Proper extraction** - Parse structured output correctly

## Confidence Level

ðŸŸ¢ **High confidence** - This was the root cause. The model literally couldn't understand the English prompt we were using!

---

## Files Changed

- âœ… [evaluate_mtup_model.py:62-114](evaluate_mtup_model.py#L62-L114) - Fixed prompt format
- âœ… Commit: `863923e` - "CRITICAL FIX: Use correct Vietnamese prompt from training"

## Commit History

1. `f50aac5` - Initial temperature fix (didn't work - wrong approach)
2. `559c998` - Tried greedy decoding (still wrong prompt)
3. `863923e` - **CRITICAL FIX** - Vietnamese prompt (should work!)
