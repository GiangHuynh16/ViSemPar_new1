# ğŸš¨ PHÃ‚N TÃCH Váº¤N Äá»€ VÃ€ GIáº¢I PHÃP

## TÃ³m táº¯t

Model "fixed" vá»«a train ra káº¿t quáº£ **THáº¢M Há»ŒA**:
- **Old model (buggy):** 124/150 valid AMRs (82.7%)
- **New model (fixed):** 8/150 valid AMRs (5.3%)
- **Regression:** -77.4% âŒ

NguyÃªn nhÃ¢n: **3 bugs nghiÃªm trá»ng** trong code training vÃ  prediction.

---

## ğŸ› Bug #1: Instruction Masking HOÃ€N TOÃ€N SAI (CRITICAL)

### Váº¥n Ä‘á»

File: [train_baseline_fixed.py:243-253](train_baseline_fixed.py#L243-L253)

Code cÅ© (SAI):
```python
# Tokenize full text
full_text = prompt + amr + tokenizer.eos_token
encoding = self.tokenizer(full_text, ...)
input_ids = encoding['input_ids'].squeeze()
labels = input_ids.clone()

# Tokenize prompt RIÃŠNG BIá»†T
prompt_encoding = self.tokenizer(prompt, ...)
prompt_length = len(prompt_encoding['input_ids'][0])

# Mask dÃ¹ng Ä‘á»™ dÃ i tá»« tokenization riÃªng biá»‡t
labels[:prompt_length] = -100  # SAI HOÃ€N TOÃ€N!
```

### Táº¡i sao sai?

Tokenizer **phá»¥ thuá»™c context**!

VÃ­ dá»¥:
- Tokenize `"Hello World"` â†’ `[Hello, World]`
- Tokenize `"Hello"` + `"World"` riÃªng â†’ `[Hello]` + `[World]` (khÃ¡c nhau!)

Do Ä‘Ã³ `prompt_length` tÃ­nh tá»« tokenization riÃªng **KHÃ”NG pháº£i** lÃ  vá»‹ trÃ­ káº¿t thÃºc prompt trong full text!

### Háº­u quáº£

- Model há»c cáº£ instruction (Ä‘Ã¡ng láº½ pháº£i mask)
- Model KHÃ”NG há»c má»™t pháº§n AMR (Ä‘Ã¡ng láº½ pháº£i train)
- Output hoÃ n toÃ n broken

### âœ… Fix Ä‘Ã£ apply

File: [train_baseline_fixed.py:227-270](train_baseline_fixed.py#L227-L270)

```python
# Encode tá»«ng pháº§n KHÃ”NG cÃ³ special tokens Ä‘á»ƒ trÃ¡nh mismatch
prompt_ids = self.tokenizer.encode(prompt, add_special_tokens=False)
amr_ids = self.tokenizer.encode(amr, add_special_tokens=False)
eos_ids = self.tokenizer.encode(self.tokenizer.eos_token, add_special_tokens=False)

# GhÃ©p láº¡i
full_ids = prompt_ids + amr_ids + eos_ids

# BÃ¢y giá» biáº¿t CHÃNH XÃC prompt káº¿t thÃºc á»Ÿ Ä‘Ã¢u
prompt_end = len(prompt_ids)
labels = input_ids.copy()
labels[:prompt_end] = -100  # ÄÃšNG!
```

---

## ğŸ› Bug #2: Check Parenthesis Balance SAI (CRITICAL)

### Váº¥n Ä‘á»

File: [predict_baseline_fixed.py:137-146](predict_baseline_fixed.py#L137-L146) (Ä‘Ã£ fix)

Code cÅ© (SAI):
```python
for line in lines:
    if not found_amr_end:
        amr_lines.append(line)
        if ')' in line:
            # SAI: Äáº¿m trong string Gá»C, khÃ´ng pháº£i accumulated!
            open_count = amr.count('(')  # <-- SAI!
            close_count = amr.count(')')
            if open_count == close_count:
                found_amr_end = True
```

### Táº¡i sao sai?

Code check balance trong **toÃ n bá»™ AMR gá»‘c**, khÃ´ng pháº£i trong **pháº§n Ä‘Ã£ tÃ­ch lÅ©y**.

â†’ Logic "dá»«ng khi balanced" **KHÃ”NG BAO GIá»œ HOáº T Äá»˜NG**

### Háº­u quáº£

- Model output bao gá»“m explanation vÃ  garbage
- AMRs bá»‹ malformed
- 91.3% invalid rate

### âœ… Fix Ä‘Ã£ apply

```python
for line in lines:
    if not found_amr_end:
        amr_lines.append(line)
        if ')' in line:
            # ÄÃšNG: Check trong accumulated text
            accumulated = '\n'.join(amr_lines)
            open_count = accumulated.count('(')
            close_count = accumulated.count(')')
            if open_count == close_count and open_count > 0:
                found_amr_end = True
```

---

## ğŸ› Bug #3: Overfitting - Loss QuÃ¡ Tháº¥p

### Váº¥n Ä‘á»

Training loss cuá»‘i: **0.0011** (cá»±c ká»³ tháº¥p!)

### Táº¡i sao lÃ  váº¥n Ä‘á»?

Loss tháº¥p Ä‘áº¿n váº­y = **overfitting nghiÃªm trá»ng**:
- Model **thuá»™c lÃ²ng** training examples
- Model KHÃ”NG há»c Ä‘Æ°á»£c pattern
- Fail hoÃ n toÃ n trÃªn test data

### Háº­u quáº£

- 91.3% invalid AMRs
- KhÃ´ng generalize Ä‘Æ°á»£c Penman format rules
- Bá»‹ broken trÃªn unseen sentences

### ğŸ’¡ Giáº£i phÃ¡p

1. **Sá»­ dá»¥ng early checkpoint** thay vÃ¬ checkpoint cuá»‘i:
   - Checkpoint-400 thay vÃ¬ checkpoint-1600
   - Loss cao hÆ¡n = generalize tá»‘t hÆ¡n

2. **Hoáº·c retrain vá»›i:**
   - Fewer epochs (hiá»‡n táº¡i: 3 epochs Ã— 545 steps = 1635 total)
   - Higher learning rate decay
   - More weight decay/dropout

---

## ğŸ“Š So sÃ¡nh Old vs New

| Metric | Old "Buggy" | New "Fixed" (Bug) | New "Fixed" (Real Fix) |
|--------|-------------|-------------------|------------------------|
| Valid AMRs | 124/150 (82.7%) | 8/150 (5.3%) | **ChÆ°a test** |
| Invalid AMRs | 26/150 (17.3%) | 137/150 (91.3%) | **ChÆ°a test** |
| Unmatched parens | 26 | 137 | **ChÆ°a test** |
| Missing samples | 0 | 2 | **Fixed vá»›i error handling** |
| Training loss | Unknown | 0.0011 (overfitted) | **ChÆ°a train** |

---

## ğŸ¯ Káº¿ hoáº¡ch hÃ nh Ä‘á»™ng

### Option A: Retrain vá»›i fixes má»›i (KHUYáº¾N NGHá»Š)

1. âœ… **Fixed Bug #1** - Instruction masking corrected
2. âœ… **Fixed Bug #2** - Balance check corrected
3. âœ… **Fixed Bug #5** - Added error handling
4. â³ **Validate training data** - Äáº£m báº£o khÃ´ng cÃ³ lá»—i trong data
5. â³ **Retrain model** - Vá»›i code Ä‘Ã£ fix
6. â³ **Test early checkpoint** - TrÃ¡nh overfitting

**Æ¯á»›c tÃ­nh thá»i gian:** ~4-5 giá» training

**Rá»§i ro:** CÃ³ thá»ƒ váº«n cáº§n Ä‘iá»u chá»‰nh hyperparameters

### Option B: DÃ¹ng model cÅ© táº¡m thá»i

Model cÅ© (82.7% valid) **Tá»T HÆ N NHIá»€U** so vá»›i model má»›i (5.3% valid).

â†’ CÃ³ thá»ƒ dÃ¹ng táº¡m trong khi fix vÃ  retrain.

### Option C: Validate trÆ°á»›c khi retrain

1. Cháº¡y diagnostic script trÃªn server
2. Validate training data quality
3. Test fix vá»›i sample nhá» (10 examples)
4. Confirm instruction masking works
5. Sau Ä‘Ã³ má»›i retrain full

**Æ¯á»›c tÃ­nh thá»i gian:** ~1-2 giá» validation + 4-5 giá» training

**Æ¯u Ä‘iá»ƒm:** An toÃ n hÆ¡n, Ä‘áº£m báº£o fix Ä‘Ãºng trÆ°á»›c khi train

---

## ğŸ“ Files Ä‘Ã£ update

### 1. train_baseline_fixed.py
- âœ… Fixed instruction masking (Bug #1)
- âœ… Sá»­ dá»¥ng `encode(..., add_special_tokens=False)`
- âœ… TÃ­nh chÃ­nh xÃ¡c vá»‹ trÃ­ káº¿t thÃºc prompt

### 2. predict_baseline_fixed.py
- âœ… Fixed balance check (Bug #2)
- âœ… Check accumulated text, khÃ´ng pháº£i original
- âœ… Added error handling cho missing samples (Bug #5)

### 3. diagnose_tokenization.py (NEW)
- âœ… Script Ä‘á»ƒ test tokenization mismatch
- â³ Cáº§n cháº¡y trÃªn server Ä‘á»ƒ confirm fix

### 4. BUGS_IDENTIFIED.md (NEW)
- âœ… Chi tiáº¿t ká»¹ thuáº­t vá» cÃ¡c bugs
- âœ… PhÃ¢n tÃ­ch root cause
- âœ… So sÃ¡nh old vs new

---

## ğŸš€ Next Steps

### Ngay láº­p tá»©c

```bash
# 1. Push code lÃªn server
git add train_baseline_fixed.py predict_baseline_fixed.py diagnose_tokenization.py BUGS_IDENTIFIED.md CRITICAL_ANALYSIS_AND_FIXES.md
git commit -m "Fix critical bugs in instruction masking and prediction"
git push

# 2. SSH vÃ o server
ssh islabworker2@islab-server2

# 3. Pull updates
cd /mnt/nghiepth/giangha/visempar/ViSemPar_new1
git pull

# 4. Validate training data
conda activate baseline_final
python validate_vietnamese_output.py --file data/train_amr_1.txt
python validate_vietnamese_output.py --file data/train_amr_2.txt

# 5. Test tokenization fix
python diagnose_tokenization.py

# 6. Náº¿u validate pass â†’ Retrain
bash TRAIN_BASELINE_FIXED.sh
```

### Trong quÃ¡ trÃ¬nh training

**GiÃ¡m sÃ¡t:**
- Check training loss khÃ´ng xuá»‘ng quÃ¡ tháº¥p (<0.01)
- Náº¿u loss < 0.05, consider stopping early
- Save checkpoints má»—i 200 steps

**Dá»± phÃ²ng:**
- Náº¿u model váº«n bad, thá»­ checkpoint-200, checkpoint-400
- So sÃ¡nh validation predictions vá»›i ground truth
- CÃ³ thá»ƒ cáº§n Ä‘iá»u chá»‰nh learning rate hoáº·c epochs

---

## ğŸ’¡ BÃ i há»c rÃºt ra

1. **Tokenization phá»¥ thuá»™c context** - KhÃ´ng thá»ƒ tokenize riÃªng rá»“i tÃ­nh Ä‘á»™ dÃ i
2. **Validation quan trá»ng** - Pháº£i test thoroughly trÆ°á»›c khi train
3. **Loss tháº¥p â‰  model tá»‘t** - Overfitting nguy hiá»ƒm
4. **Error handling cáº§n thiáº¿t** - Pháº£i catch errors Ä‘á»ƒ debug

---

## â“ Questions?

Báº¡n muá»‘n:

**A.** Retrain ngay vá»›i fixes má»›i (4-5 giá»)

**B.** Validate ká»¹ trÆ°á»›c (1-2 giá») rá»“i má»›i train (4-5 giá»)

**C.** DÃ¹ng model cÅ© táº¡m, research thÃªm trÆ°á»›c khi retrain

**D.** KhÃ¡c (Ä‘á» xuáº¥t cá»§a báº¡n)

---

## ğŸ“Œ Status

**Bugs identified:** 5/5 âœ…

**Bugs fixed:** 3/5 âœ…
- âœ… Bug #1 (instruction masking)
- âœ… Bug #2 (balance check)
- â³ Bug #3 (overfitting) - cáº§n test checkpoint
- â³ Bug #4 (data quality) - cáº§n validate
- âœ… Bug #5 (missing samples)

**Code updated:** âœ…

**Ready to retrain:** â³ (pending validation)

**Current model:** âŒ BROKEN (5.3% valid)

**Old model:** âš ï¸ Available fallback (82.7% valid)
