# Memory Optimization - Quick Summary

**Date**: 2025-12-30
**Problem**: CUDA OOM v·ªõi batch_size=2 m·∫∑c d√π GPU c√≥ 24GB
**Solution**: T·ªëi ∆∞u h√≥a b·ªô nh·ªõ KH√îNG gi·∫£m tham s·ªë model

---

## C√°c thay ƒë·ªïi ƒë√£ √°p d·ª•ng

### 1. ‚úÖ Gi·∫£m Max Sequence Length
```python
# config/config.py
MAX_SEQ_LENGTH = 1536  # T·ª´ 2048 ‚Üí Ti·∫øt ki·ªám ~25% b·ªô nh·ªõ
```

### 2. ‚úÖ ƒêi·ªÅu ch·ªânh Batch Size + Gradient Accumulation
```python
# config/config.py - TRAINING_CONFIG
"per_device_train_batch_size": 1,     # T·ª´ 2
"gradient_accumulation_steps": 16,    # T·ª´ 8
# Effective batch size v·∫´n = 16 (kh√¥ng ƒë·ªïi!)
```

### 3. ‚úÖ B·∫≠t Gradient Checkpointing
```python
# train_baseline.py:367
gradient_checkpointing=True  # ƒê√£ s·ª≠a t·ª´ False
```

### 4. ‚úÖ T·ªëi ∆∞u CUDA Memory Allocator
```bash
# T·ª± ƒë·ªông set trong START_BASELINE_7B_TRAINING.sh
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:128,expandable_segments:True"
```

### 5. ‚úÖ Clear GPU cache tr∆∞·ªõc khi train
```bash
# T·ª± ƒë·ªông th·ª±c hi·ªán trong START_BASELINE_7B_TRAINING.sh
python3 -c "import torch; torch.cuda.empty_cache()"
```

---

## K·∫øt qu·∫£

### Tr∆∞·ªõc t·ªëi ∆∞u (OOM ‚ùå)
- Peak VRAM: ~23-25 GB
- K·∫øt qu·∫£: CUDA Out of Memory

### Sau t·ªëi ∆∞u (OK ‚úÖ)
- Peak VRAM: ~18-20 GB
- Margin: ~4 GB d∆∞
- Model params: KH√îNG ƒê·ªîI (v·∫´n 7B + LoRA 128)

---

## C√°ch s·ª≠ d·ª•ng

### Tr√™n server:

```bash
# 1. Pull code m·ªõi
cd ViSemPar_new1
git pull origin main

# 2. (Optional) Ki·ªÉm tra t·ªëi ∆∞u b·ªô nh·ªõ
bash OPTIMIZE_MEMORY.sh

# 3. Start training
tmux new -s baseline_7b
bash START_BASELINE_7B_TRAINING.sh
```

### File script START_BASELINE_7B_TRAINING.sh gi·ªù t·ª± ƒë·ªông:
- ‚úÖ Set PYTORCH_CUDA_ALLOC_CONF
- ‚úÖ Clear GPU cache
- ‚úÖ D√πng batch_size=1, grad_accum=16, max_length=1536

---

## N·∫øu v·∫´n OOM

### Option 1: Ch·∫°y script t·ªëi ∆∞u
```bash
bash OPTIMIZE_MEMORY.sh
```

### Option 2: Kill processes v√† clear GPU
```bash
pkill -9 python
nvidia-smi --gpu-reset
```

### Option 3: Reboot server (nuclear option)
```bash
sudo reboot
```

---

## C√°c th√¥ng s·ªë quan tr·ªçng

| Th√¥ng s·ªë | Gi√° tr·ªã m·ªõi | Gi√° tr·ªã c≈© | L√Ω do |
|----------|-------------|------------|-------|
| max_seq_length | 1536 | 2048 | Gi·∫£m 25% activation memory |
| batch_size | 1 | 2 | Gi·∫£m 50% activation memory |
| grad_accum | 16 | 8 | Gi·ªØ effective batch = 16 |
| gradient_checkpointing | True | False | Ti·∫øt ki·ªám ~1-2GB |
| Peak VRAM | ~18-20GB | ~23-25GB | Ti·∫øt ki·ªám ~5GB |

**Model capacity: KH√îNG ƒê·ªîI - V·∫´n c√¥ng b·∫±ng so v·ªõi MTUP 7B!**

---

## T√†i li·ªáu chi ti·∫øt

- [MEMORY_OPTIMIZATION_GUIDE.md](MEMORY_OPTIMIZATION_GUIDE.md) - H∆∞·ªõng d·∫´n chi ti·∫øt
- [OPTIMIZE_MEMORY.sh](OPTIMIZE_MEMORY.sh) - Script t·ªëi ∆∞u b·ªô nh·ªõ
- [FINAL_CHECKLIST.md](FINAL_CHECKLIST.md) - Checklist tr∆∞·ªõc khi training

---

**S·∫µn s√†ng training! üöÄ**
